<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Applied Statistics II</title>
  <meta name="description" content="Course notes for MATH 456 at CSU Chico">
  <meta name="generator" content="bookdown 0.5.15 and GitBook 2.6.7">

  <meta property="og:title" content="Applied Statistics II" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for MATH 456 at CSU Chico" />
  <meta name="github-repo" content="norcalbiostat/MATH456_notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Applied Statistics II" />
  
  <meta name="twitter:description" content="Course notes for MATH 456 at CSU Chico" />
  

<meta name="author" content="Robin A. Donatello and Edward A. Roualdes">


<meta name="date" content="2018-01-18">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="fitting-glms-in-r.html">
<link rel="next" href="categorical-data.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Applied Statistics II course notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="data-prep.html"><a href="data-prep.html"><i class="fa fa-check"></i><b>1</b> Preparing Data for Analysis</a><ul>
<li class="chapter" data-level="1.1" data-path="reproducible-workflows.html"><a href="reproducible-workflows.html"><i class="fa fa-check"></i><b>1.1</b> Reproducible Workflows</a></li>
<li class="chapter" data-level="1.2" data-path="identifying-variable-types.html"><a href="identifying-variable-types.html"><i class="fa fa-check"></i><b>1.2</b> Identifying Variable Types</a></li>
<li class="chapter" data-level="1.3" data-path="data-editing-and-recoding.html"><a href="data-editing-and-recoding.html"><i class="fa fa-check"></i><b>1.3</b> Data Editing and Recoding</a></li>
<li class="chapter" data-level="1.4" data-path="outliers.html"><a href="outliers.html"><i class="fa fa-check"></i><b>1.4</b> Outliers</a></li>
<li class="chapter" data-level="1.5" data-path="data-transformations.html"><a href="data-transformations.html"><i class="fa fa-check"></i><b>1.5</b> Data Transformations</a></li>
<li class="chapter" data-level="1.6" data-path="selecting-appropriate-analysis.html"><a href="selecting-appropriate-analysis.html"><i class="fa fa-check"></i><b>1.6</b> Selecting Appropriate Analysis</a></li>
<li class="chapter" data-level="1.7" data-path="wide-vs-long-data.html"><a href="wide-vs-long-data.html"><i class="fa fa-check"></i><b>1.7</b> Wide vs. Long data</a></li>
</ul></li>
<li class="part"><span><b>I Regression Modeling</b></span></li>
<li class="chapter" data-level="2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>2</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="2.1" data-path="mathmatical-model.html"><a href="mathmatical-model.html"><i class="fa fa-check"></i><b>2.1</b> Mathmatical Model</a></li>
<li class="chapter" data-level="2.2" data-path="parameter-estimates.html"><a href="parameter-estimates.html"><i class="fa fa-check"></i><b>2.2</b> Parameter Estimates</a></li>
<li class="chapter" data-level="2.3" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>2.3</b> Interval estimation</a></li>
<li class="chapter" data-level="2.4" data-path="corelation-coefficient.html"><a href="corelation-coefficient.html"><i class="fa fa-check"></i><b>2.4</b> Corelation Coefficient</a></li>
<li class="chapter" data-level="2.5" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>2.5</b> Assumptions</a></li>
<li class="chapter" data-level="2.6" data-path="example.html"><a href="example.html"><i class="fa fa-check"></i><b>2.6</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>3</b> Multiple Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="types-of-x-variables.html"><a href="types-of-x-variables.html"><i class="fa fa-check"></i><b>3.1</b> Types of X variables</a></li>
<li class="chapter" data-level="3.2" data-path="mathematical-model.html"><a href="mathematical-model.html"><i class="fa fa-check"></i><b>3.2</b> Mathematical Model</a></li>
<li class="chapter" data-level="3.3" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i><b>3.3</b> Parameter Estimation</a></li>
<li class="chapter" data-level="3.4" data-path="example-1.html"><a href="example-1.html"><i class="fa fa-check"></i><b>3.4</b> Example</a></li>
<li class="chapter" data-level="3.5" data-path="model-diagnostics.html"><a href="model-diagnostics.html"><i class="fa fa-check"></i><b>3.5</b> Model Diagnostics</a></li>
<li class="chapter" data-level="3.6" data-path="multicollinearity.html"><a href="multicollinearity.html"><i class="fa fa-check"></i><b>3.6</b> Multicollinearity</a></li>
<li class="chapter" data-level="3.7" data-path="what-to-watch-out-for.html"><a href="what-to-watch-out-for.html"><i class="fa fa-check"></i><b>3.7</b> What to watch out for</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>4</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="fitting-glms-in-r.html"><a href="fitting-glms-in-r.html"><i class="fa fa-check"></i><b>4.1</b> Fitting GLMs in R</a></li>
<li class="chapter" data-level="4.2" data-path="binary-data.html"><a href="binary-data.html"><i class="fa fa-check"></i><b>4.2</b> Binary Data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="binary-data.html"><a href="binary-data.html#example-the-effect-of-gender-on-depression"><i class="fa fa-check"></i><b>4.2.1</b> Example: The effect of gender on Depression</a></li>
<li class="chapter" data-level="4.2.2" data-path="binary-data.html"><a href="binary-data.html#multiple-logistic-regression"><i class="fa fa-check"></i><b>4.2.2</b> Multiple Logistic Regression</a></li>
<li class="chapter" data-level="4.2.3" data-path="binary-data.html"><a href="binary-data.html#interpretation"><i class="fa fa-check"></i><b>4.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="4.2.4" data-path="binary-data.html"><a href="binary-data.html#goodness-of-fit"><i class="fa fa-check"></i><b>4.2.4</b> Goodness of Fit</a></li>
<li class="chapter" data-level="4.2.5" data-path="binary-data.html"><a href="binary-data.html#classification"><i class="fa fa-check"></i><b>4.2.5</b> Classification</a></li>
<li class="chapter" data-level="4.2.6" data-path="binary-data.html"><a href="binary-data.html#calculating-predictions"><i class="fa fa-check"></i><b>4.2.6</b> Calculating predictions</a></li>
<li class="chapter" data-level="4.2.7" data-path="binary-data.html"><a href="binary-data.html#model-performance"><i class="fa fa-check"></i><b>4.2.7</b> Model Performance</a></li>
<li class="chapter" data-level="4.2.8" data-path="binary-data.html"><a href="binary-data.html#roc-curves"><i class="fa fa-check"></i><b>4.2.8</b> ROC Curves</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="categorical-data.html"><a href="categorical-data.html"><i class="fa fa-check"></i><b>4.3</b> Categorical Data</a></li>
<li class="chapter" data-level="4.4" data-path="count-data.html"><a href="count-data.html"><i class="fa fa-check"></i><b>4.4</b> Count Data</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="model-building.html"><a href="model-building.html"><i class="fa fa-check"></i><b>5</b> Model Building</a><ul>
<li class="chapter" data-level="5.1" data-path="categorical-predictors.html"><a href="categorical-predictors.html"><i class="fa fa-check"></i><b>5.1</b> Categorical Predictors</a><ul>
<li class="chapter" data-level="5.1.1" data-path="categorical-predictors.html"><a href="categorical-predictors.html#factor-variable-coding"><i class="fa fa-check"></i><b>5.1.1</b> Factor variable coding</a></li>
<li class="chapter" data-level="5.1.2" data-path="categorical-predictors.html"><a href="categorical-predictors.html#wald-test"><i class="fa fa-check"></i><b>5.1.2</b> Wald test</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="stratification.html"><a href="stratification.html"><i class="fa fa-check"></i><b>5.2</b> Stratification</a></li>
<li class="chapter" data-level="5.3" data-path="moderation.html"><a href="moderation.html"><i class="fa fa-check"></i><b>5.3</b> Moderation</a><ul>
<li class="chapter" data-level="5.3.1" data-path="moderation.html"><a href="moderation.html#example-2"><i class="fa fa-check"></i><b>5.3.1</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>5.4</b> Interactions</a><ul>
<li class="chapter" data-level="5.4.1" data-path="interactions.html"><a href="interactions.html#example-3"><i class="fa fa-check"></i><b>5.4.1</b> Example</a></li>
<li class="chapter" data-level="5.4.2" data-path="interactions.html"><a href="interactions.html#example-4"><i class="fa fa-check"></i><b>5.4.2</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="variable-selection-process.html"><a href="variable-selection-process.html"><i class="fa fa-check"></i><b>5.5</b> Variable Selection Process</a><ul>
<li class="chapter" data-level="5.5.1" data-path="variable-selection-process.html"><a href="variable-selection-process.html#confounding"><i class="fa fa-check"></i><b>5.5.1</b> Confounding</a></li>
<li class="chapter" data-level="5.5.2" data-path="variable-selection-process.html"><a href="variable-selection-process.html#automated-selection-procedures"><i class="fa fa-check"></i><b>5.5.2</b> Automated selection procedures</a></li>
<li class="chapter" data-level="5.5.3" data-path="variable-selection-process.html"><a href="variable-selection-process.html#best-subsets-pma5-section-8.7"><i class="fa fa-check"></i><b>5.5.3</b> Best Subsets (PMA5 Section 8.7)</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="comparing-between-models.html"><a href="comparing-between-models.html"><i class="fa fa-check"></i><b>5.6</b> Comparing between models</a></li>
<li class="chapter" data-level="5.7" data-path="what-to-watch-out-for-1.html"><a href="what-to-watch-out-for-1.html"><i class="fa fa-check"></i><b>5.7</b> What to watch out for</a></li>
</ul></li>
<li class="part"><span><b>II Multivariate Analysis</b></span></li>
<li class="chapter" data-level="6" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>6</b> Principal Component Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="basic-idea.html"><a href="basic-idea.html"><i class="fa fa-check"></i><b>6.1</b> Basic Idea</a></li>
<li class="chapter" data-level="6.2" data-path="more-generally.html"><a href="more-generally.html"><i class="fa fa-check"></i><b>6.2</b> More Generally</a></li>
<li class="chapter" data-level="6.3" data-path="calculating-c.html"><a href="calculating-c.html"><i class="fa fa-check"></i><b>6.3</b> Calculating C</a></li>
<li class="chapter" data-level="6.4" data-path="using-the-correlation-matrix.html"><a href="using-the-correlation-matrix.html"><i class="fa fa-check"></i><b>6.4</b> Using the correlation matrix</a></li>
<li class="chapter" data-level="6.5" data-path="data-reduction.html"><a href="data-reduction.html"><i class="fa fa-check"></i><b>6.5</b> Data Reduction</a></li>
<li class="chapter" data-level="6.6" data-path="example-analysis-of-depression.html"><a href="example-analysis-of-depression.html"><i class="fa fa-check"></i><b>6.6</b> Example Analysis of depression</a></li>
<li class="chapter" data-level="6.7" data-path="use-in-multiple-regression.html"><a href="use-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.7</b> Use in Multiple Regression</a></li>
<li class="chapter" data-level="6.8" data-path="things-to-watch-out-for.html"><a href="things-to-watch-out-for.html"><i class="fa fa-check"></i><b>6.8</b> Things to watch out for</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="fa.html"><a href="fa.html"><i class="fa fa-check"></i><b>7</b> Factor Analysis</a><ul>
<li class="chapter" data-level="7.1" data-path="stuff.html"><a href="stuff.html"><i class="fa fa-check"></i><b>7.1</b> stuff</a></li>
</ul></li>
<li class="part"><span><b>III Multi-level Analysis</b></span></li>
<li class="chapter" data-level="8" data-path="RI.html"><a href="RI.html"><i class="fa fa-check"></i><b>8</b> Random Intercept Models</a></li>
<li class="chapter" data-level="9" data-path="longitudinal.html"><a href="longitudinal.html"><i class="fa fa-check"></i><b>9</b> Longitudinal Data</a></li>
<li class="chapter" data-level="10" data-path="spatial.html"><a href="spatial.html"><i class="fa fa-check"></i><b>10</b> Spatial Data</a></li>
<li class="part"><span><b>IV Other Topics</b></span></li>
<li class="chapter" data-level="11" data-path="mda.html"><a href="mda.html"><i class="fa fa-check"></i><b>11</b> Missing Data</a><ul>
<li class="chapter" data-level="11.1" data-path="identifying-missing-data.html"><a href="identifying-missing-data.html"><i class="fa fa-check"></i><b>11.1</b> Identifying missing data</a><ul>
<li class="chapter" data-level="11.1.1" data-path="identifying-missing-data.html"><a href="identifying-missing-data.html#visualize-missing-patterns"><i class="fa fa-check"></i><b>11.1.1</b> Visualize missing patterns</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="effects-of-nonresponse.html"><a href="effects-of-nonresponse.html"><i class="fa fa-check"></i><b>11.2</b> Effects of Nonresponse</a></li>
<li class="chapter" data-level="11.3" data-path="missing-data-mechanisms.html"><a href="missing-data-mechanisms.html"><i class="fa fa-check"></i><b>11.3</b> Missing Data Mechanisms</a><ul>
<li class="chapter" data-level="11.3.1" data-path="missing-data-mechanisms.html"><a href="missing-data-mechanisms.html#demonstration-via-simulation"><i class="fa fa-check"></i><b>11.3.1</b> Demonstration via Simulation</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="general-strategies.html"><a href="general-strategies.html"><i class="fa fa-check"></i><b>11.4</b> General strategies</a><ul>
<li class="chapter" data-level="11.4.1" data-path="general-strategies.html"><a href="general-strategies.html#complete-cases-analysis"><i class="fa fa-check"></i><b>11.4.1</b> Complete cases analysis</a></li>
<li class="chapter" data-level="11.4.2" data-path="general-strategies.html"><a href="general-strategies.html#available-case-analysis"><i class="fa fa-check"></i><b>11.4.2</b> Available-case analysis</a></li>
<li class="chapter" data-level="11.4.3" data-path="general-strategies.html"><a href="general-strategies.html#imputation"><i class="fa fa-check"></i><b>11.4.3</b> Imputation</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="imputation-methods.html"><a href="imputation-methods.html"><i class="fa fa-check"></i><b>11.5</b> Imputation Methods</a></li>
<li class="chapter" data-level="11.6" data-path="multiple-imputation-mi.html"><a href="multiple-imputation-mi.html"><i class="fa fa-check"></i><b>11.6</b> Multiple Imputation (MI)</a><ul>
<li class="chapter" data-level="11.6.1" data-path="multiple-imputation-mi.html"><a href="multiple-imputation-mi.html#goals"><i class="fa fa-check"></i><b>11.6.1</b> Goals</a></li>
<li class="chapter" data-level="11.6.2" data-path="multiple-imputation-mi.html"><a href="multiple-imputation-mi.html#technique"><i class="fa fa-check"></i><b>11.6.2</b> Technique</a></li>
<li class="chapter" data-level="11.6.3" data-path="multiple-imputation-mi.html"><a href="multiple-imputation-mi.html#mi-as-a-paradigm"><i class="fa fa-check"></i><b>11.6.3</b> MI as a paradigm</a></li>
<li class="chapter" data-level="11.6.4" data-path="multiple-imputation-mi.html"><a href="multiple-imputation-mi.html#inference-on-mi"><i class="fa fa-check"></i><b>11.6.4</b> Inference on MI</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="multiple-imputation-using-chained-equations-mice.html"><a href="multiple-imputation-using-chained-equations-mice.html"><i class="fa fa-check"></i><b>11.7</b> Multiple Imputation using Chained Equations (MICE)</a><ul>
<li class="chapter" data-level="11.7.1" data-path="multiple-imputation-using-chained-equations-mice.html"><a href="multiple-imputation-using-chained-equations-mice.html#visualize-imputations"><i class="fa fa-check"></i><b>11.7.1</b> Visualize Imputations</a></li>
<li class="chapter" data-level="11.7.2" data-path="multiple-imputation-using-chained-equations-mice.html"><a href="multiple-imputation-using-chained-equations-mice.html#calculating-bias"><i class="fa fa-check"></i><b>11.7.2</b> Calculating bias</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="final-thoughts.html"><a href="final-thoughts.html"><i class="fa fa-check"></i><b>11.8</b> Final thoughts</a></li>
<li class="chapter" data-level="11.9" data-path="additional-references.html"><a href="additional-references.html"><i class="fa fa-check"></i><b>11.9</b> Additional References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Applied Statistics II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="binary-data" class="section level2">
<h2><span class="header-section-number">4.2</span> Binary Data</h2>
<p>Goals:</p>
<ul>
<li>Assess the impact selected covariates have on the probability of an outcome occurring.</li>
<li>Predict the likelihood / chance / probability of an event occurring given a certain covariate pattern.</li>
</ul>
<p>Binary data can be fit using a <em>Logistic Model</em> or a <em>Probit Model</em>.</p>
<p>Consider an outcome variable <span class="math inline">\(Y\)</span> with two levels: Y = 1 if event, = 0 if no event.</p>
<p>Let <span class="math inline">\(p_{i} = P(y_{i}=1)\)</span>.</p>
<p>The logistic model relates the probability of an event based on a linear combination of X’s.</p>
<p><span class="math display">\[
log\left(
\frac{p_{i}}{1-p_{i}}
\right) = \beta_{0} + \beta_{1}x_{1i} + \beta_{2}x_{2i} + \ldots + \beta_{p}x_{pi}
\]</span></p>
<p>Since the <em>odds</em> are defined as the probability an event occurs divided by the probability it does not occur: <span class="math inline">\((p/(1-p))\)</span>, the function <span class="math inline">\(log\left(\frac{p_{i}}{1-p_{i}}\right)\)</span> is also known as the <em>log odds</em>, or more commonly called the <strong><em>logit</em></strong>. This is the <em>link</em> function for the logistic regression model.</p>
<p><img src="GLM_files/figure-html/unnamed-chunk-3-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>This in essence takes a binary outcome 0/1 variable, turns it into a continuous probability (which only has a range from 0 to 1) Then the logit(p) has a continuous distribution ranging from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>, which is the same form as a Multiple Linear Regression (continuous outcome modeled on a set of covariates)</p>
<p>Back solving the logistic model for <span class="math inline">\(p_{i} = e^{\beta X} / (1+e^{\beta X})\)</span> gives us the probability of an event.</p>
<p><span class="math display">\[
p_{i} = \frac{e^{\beta_{0} + \beta_{1}x_{1i} + \beta_{2}x_{2i} + \ldots + \beta_{p}x_{pi}}}
{1 + e^{\beta_{0} + \beta_{1}x_{1i} + \beta_{2}x_{2i} + \ldots + \beta_{p}x_{pi}}}
\]</span></p>

<div class="rmdtip">
The probit function uses the inverse CDF for the normal distribution as the link function.
</div>

<div id="example-the-effect-of-gender-on-depression" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Example: The effect of gender on Depression</h3>
<p>Is gender associated with depression? Read in the <code>depression</code> data and recode sex to be an indicator of being male.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">depress &lt;-<span class="st"> </span><span class="kw">read.delim</span>(<span class="st">&quot;https://norcalbiostat.netlify.com/data/depress_081217.txt&quot;</span>)
<span class="kw">names</span>(depress) &lt;-<span class="st"> </span><span class="kw">tolower</span>(<span class="kw">names</span>(depress)) <span class="co"># make all variable names lower case. </span></code></pre></div>
<ul>
<li>Binary outcome variable: Symptoms of Depression (<code>cases</code>)</li>
<li>Binary predictor variable: Gender (<code>sex</code>) as an indicator of being female</li>
</ul>
<p>The outcome <span class="math inline">\(y\)</span> is a 0/1 Bernoulli random variable. The sum of a vector of Bernoulli’s (<span class="math inline">\(\sum_{i=1}^{n}y_{i}\)</span>) has a Binomial distribution. When we specify that <code>family = &quot;binomial&quot;</code> the <code>glm()</code> function auto-assigns “logit” link function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dep_sex_model &lt;-<span class="st"> </span><span class="kw">glm</span>(cases <span class="op">~</span><span class="st"> </span>sex, <span class="dt">data=</span>depress, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span>(dep_sex_model)
## 
## Call:
## glm(formula = cases ~ sex, family = &quot;binomial&quot;, data = depress)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.7023  -0.7023  -0.4345  -0.4345   2.1941  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -2.3125     0.3315  -6.976 3.04e-12 ***
## sex           1.0386     0.3767   2.757  0.00583 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.12  on 293  degrees of freedom
## Residual deviance: 259.40  on 292  degrees of freedom
## AIC: 263.4
## 
## Number of Fisher Scoring iterations: 5</code></pre></div>
<p>We exponentiate the coefficients to back transform the <span class="math inline">\(\beta\)</span> estimates into Odds Ratios</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(dep_sex_model))
## (Intercept)         sex 
##   0.0990099   2.8251748</code></pre></div>
<p>Females have 2.8 times the odds of showing signs of depression compared to males.</p>
<p><strong>Confidence Intervals</strong> The OR is <strong>not</strong> a linear function of the <span class="math inline">\(x&#39;s\)</span>, but <span class="math inline">\(\beta\)</span> is. This means that a CI for the OR is created by calculating a CI for <span class="math inline">\(\beta\)</span>, and then exponentiating the endpoints. A 95% CI for the OR can be calculated as:</p>
<p><span class="math display">\[e^{\hat{\beta} \pm 1.96 SE_{\beta}} \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">confint</span>(dep_sex_model))
##                  2.5 %    97.5 %
## (Intercept) 0.04843014 0.1801265
## sex         1.39911056 6.2142384</code></pre></div>
</div>
<div id="multiple-logistic-regression" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Multiple Logistic Regression</h3>
<p>Just like multiple linear regression, additional predictors are simply included in the model using a <code>+</code> symbol.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mvmodel &lt;-<span class="st"> </span><span class="kw">glm</span>(cases <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span>sex, <span class="dt">data=</span>depress, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span>(mvmodel)
## 
## Call:
## glm(formula = cases ~ age + income + sex, family = &quot;binomial&quot;, 
##     data = depress)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.0249  -0.6524  -0.5050  -0.3179   2.5305  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept) -0.67646    0.57881  -1.169  0.24253   
## age         -0.02096    0.00904  -2.318  0.02043 * 
## income      -0.03656    0.01409  -2.595  0.00946 **
## sex          0.92945    0.38582   2.409  0.01600 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.12  on 293  degrees of freedom
## Residual deviance: 247.54  on 290  degrees of freedom
## AIC: 255.54
## 
## Number of Fisher Scoring iterations: 5</code></pre></div>
<ul>
<li>The sign of the <span class="math inline">\(\beta\)</span> coefficients can be interpreted in the same manner as with linear regression.</li>
<li>The odds of being depressed are less if the respondent has a higher income and is older, and higher if the respondent is female.</li>
</ul>
</div>
<div id="interpretation" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Interpretation</h3>
<ul>
<li>The OR provides a directly understandable statistic for the relationship between <span class="math inline">\(y\)</span> and a specific <span class="math inline">\(x\)</span> given all other <span class="math inline">\(x\)</span>’s in the model are fixed.</li>
<li>For a continuous variable X with slope coefficient <span class="math inline">\(\beta\)</span>, the quantity <span class="math inline">\(e^{b}\)</span> is interpreted as the ratio of the odds for a person with value (X+1) relative to the odds for a person with value X.</li>
<li><span class="math inline">\(exp(kb)\)</span> is the incremental odds ratio corresponding to an increase of <span class="math inline">\(k\)</span> units in the variable X, assuming that the values of all other X variables remain unchanged.</li>
</ul>
<p><strong>Where does <span class="math inline">\(OR = e^{\beta}\)</span> come from?</strong></p>
<p>The full model is: <span class="math display">\[log(odds) = -0.676 - 0.02096*age - .03656*income + 0.92945*gender\]</span></p>
<p>We want to calculate the Odds Ratio of depression for women compared to men. <span class="math display">\[ OR = \frac{Odds (Y=1|F)}{Odds (Y=1|M)} \]</span></p>
<p>Write out the equations for men and women separately. <span class="math display">\[ = \frac{e^{-0.676 - 0.02096*age - .03656*income + 0.92945(1)}}
          {e^{-0.676 - 0.02096*age - .03656*income + 0.92945(0)}}\]</span></p>
<p>Applying rules of exponents to simplify. <span class="math display">\[ = \frac{e^{-0.676}e^{- 0.02096*age}e^{- .03656*income}e^{0.92945(1)}}
          {e^{-0.676}e^{- 0.02096*age}e^{- .03656*income}e^{0.92945(0)}}\]</span></p>
<p><span class="math display">\[ = \frac{e^{0.92945(1)}}
          {e^{0.92945(0)}}\]</span></p>
<p><span class="math display">\[ = e^{0.92945} \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(.<span class="dv">92945</span>)
## [1] 2.533116
<span class="kw">exp</span>(<span class="kw">coef</span>(mvmodel)[<span class="dv">4</span>])
##      sex 
## 2.533112</code></pre></div>
<p>The odds of a female being depressed are 2.53 times greater than the odds for Males after adjusting for the linear effects of age and income (p=.016).</p>
<div id="effect-of-a-k-unit-change" class="section level4">
<h4><span class="header-section-number">4.2.3.1</span> Effect of a k unit change</h4>
<p>Sometimes a 1 unit change in a continuous variable is not meaningful.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="kw">coef</span>(mvmodel))
## (Intercept)         age      income         sex 
##   0.5084157   0.9792605   0.9640969   2.5331122
<span class="kw">exp</span>(<span class="kw">confint</span>(mvmodel))
##                 2.5 %    97.5 %
## (Intercept) 0.1585110 1.5491849
## age         0.9615593 0.9964037
## income      0.9357319 0.9891872
## sex         1.2293435 5.6586150</code></pre></div>
<ul>
<li>The Adjusted odds ratio (AOR) for increase of 1 year of age is 0.98 (95%CI .96, 1.0)</li>
<li>How about a 10 year increase in age? <span class="math inline">\(e^{10*\beta_{age}} = e^{-.21} = .81\)</span></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="dv">10</span><span class="op">*</span><span class="kw">coef</span>(mvmodel)[<span class="dv">2</span>])
##       age 
## 0.8109285</code></pre></div>
<p>with a confidence interval of</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">exp</span>(<span class="dv">10</span><span class="op">*</span><span class="kw">confint</span>(mvmodel)[<span class="dv">2</span>,]),<span class="dv">3</span>)
##  2.5 % 97.5 % 
##  0.676  0.965</code></pre></div>
<p>Controlling for gender and income, an individual has 0.81 (95% CI 0.68, 0.97) times the odds of being depressed compared to someone who is 10 years younger than them.</p>
<div id="example-the-relationship-between-income-employment-status-and-depression." class="section level5">
<h5><span class="header-section-number">4.2.3.1.1</span> Example: The relationship between income, employment status and depression.</h5>
<p>This example follows PMA5 Ch 12.7</p>
<p>Here I create the binary indicators of lowincome (annual income &lt;$10k/year) and underemployed (part time or unemployed).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">depress<span class="op">$</span>lowincome &lt;-<span class="st"> </span><span class="kw">ifelse</span>(depress<span class="op">$</span>income <span class="op">&lt;</span><span class="st"> </span><span class="dv">10</span>, <span class="dv">1</span>, <span class="dv">0</span>)
<span class="kw">table</span>(depress<span class="op">$</span>lowincome, depress<span class="op">$</span>income, <span class="dt">useNA=</span><span class="st">&quot;always&quot;</span>)
##       
##         2  4  5  6  7  8  9 11 12 13 15 16 18 19 20 23 24 25 26 27 28 31
##   0     0  0  0  0  0  0  0 17  2 18 24  1  1 25  3 25  2  1  1  1 19  1
##   1     7  8 10 12 18 14 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
##   &lt;NA&gt;  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
##       
##        32 35 36 37 42 45 55 65 &lt;NA&gt;
##   0     1 24  1  1  1 15  9 10    0
##   1     0  0  0  0  0  0  0  0    0
##   &lt;NA&gt;  0  0  0  0  0  0  0  0    0

depress<span class="op">$</span>underemployed &lt;-<span class="st"> </span><span class="kw">ifelse</span>(depress<span class="op">$</span>employ <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;PT&quot;</span>, <span class="st">&quot;Unemp&quot;</span>), <span class="dv">1</span>, <span class="dv">0</span> )
<span class="kw">table</span>(depress<span class="op">$</span>underemployed, depress<span class="op">$</span>employ, <span class="dt">useNA=</span><span class="st">&quot;always&quot;</span>)
##       
##         FT Houseperson In School Other  PT Retired Unemp &lt;NA&gt;
##   0    167          27         2     4   0      38     0    0
##   1      0           0         0     0  42       0    14    0
##   &lt;NA&gt;   0           0         0     0   0       0     0    0</code></pre></div>
<p>The <strong>Main Effects</strong> model assumes that the effect of income on depression is independent of employment status, and the effect of employment status on depression is independent of income.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">me_model &lt;-<span class="st"> </span><span class="kw">glm</span>(cases <span class="op">~</span><span class="st"> </span>lowincome <span class="op">+</span><span class="st"> </span>underemployed, <span class="dt">data=</span>depress, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
<span class="kw">summary</span>(me_model)
## 
## Call:
## glm(formula = cases ~ lowincome + underemployed, family = &quot;binomial&quot;, 
##     data = depress)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.9085  -0.5843  -0.5279  -0.5279   2.0197  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    -1.9003     0.2221  -8.556  &lt; 2e-16 ***
## lowincome       0.2192     0.3353   0.654  0.51322    
## underemployed   1.0094     0.3470   2.909  0.00363 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.12  on 293  degrees of freedom
## Residual deviance: 259.93  on 291  degrees of freedom
## AIC: 265.93
## 
## Number of Fisher Scoring iterations: 4</code></pre></div>
<p>To formally test whether an interaction term is necessary, we add the interaction term into the model and assess whether the coefficient for the interaction term is significantly different from zero.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">me_intx_model &lt;-<span class="st"> </span><span class="kw">glm</span>(cases <span class="op">~</span><span class="st"> </span>lowincome <span class="op">+</span><span class="st"> </span>underemployed <span class="op">+</span><span class="st"> </span>lowincome<span class="op">*</span>underemployed, <span class="dt">data=</span>depress, <span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>) 
<span class="kw">summary</span>(me_intx_model)
## 
## Call:
## glm(formula = cases ~ lowincome + underemployed + lowincome * 
##     underemployed, family = &quot;binomial&quot;, data = depress)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.3537  -0.5790  -0.5790  -0.4717   2.1219  
## 
## Coefficients:
##                         Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)              -1.7011     0.2175  -7.822 5.21e-15 ***
## lowincome                -0.4390     0.4324  -1.015  0.31005    
## underemployed             0.2840     0.4501   0.631  0.52802    
## lowincome:underemployed   2.2615     0.7874   2.872  0.00408 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 268.12  on 293  degrees of freedom
## Residual deviance: 251.17  on 290  degrees of freedom
## AIC: 259.17
## 
## Number of Fisher Scoring iterations: 4</code></pre></div>
</div>
</div>
</div>
<div id="goodness-of-fit" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Goodness of Fit</h3>
<ul>
<li>Tests to see if there is sufficient reason to believe that the logistic model does not fit (<span class="math inline">\(H_{a}\)</span>), versus it does fit (<span class="math inline">\(H_{0}\)</span>)</li>
<li>This means that a small p-value indicates that the model <em>does not fit</em> the data.</li>
<li>We’ll look specifically at the Hosmer-Lemeshow (HL) Goodness of fit (GoF) test</li>
</ul>
<div id="hl-gof" class="section level4">
<h4><span class="header-section-number">4.2.4.1</span> HL GoF</h4>
<ol style="list-style-type: decimal">
<li>Compute the probability (<span class="math inline">\(p_{i}\)</span>) of event (risk) for each observation.</li>
<li>Sort data by this <span class="math inline">\(p\)</span>.</li>
<li>Divide into <span class="math inline">\(G\)</span> equal sized groups in ascending order (G=10 is common, i.e. split into deciles)</li>
<li>Then for each group we calculate
<ul>
<li><span class="math inline">\(O_{1g}\)</span>: the observed number of events</li>
<li><span class="math inline">\(E_{1g}\)</span>: the expected number of events as the <span class="math inline">\(\sum_{i} p_{ig}\)</span></li>
<li><span class="math inline">\(O_{0g}\)</span>: the observed number of non-events</li>
<li><span class="math inline">\(E_{0g}\)</span>: the expected number of events as the <span class="math inline">\(1-\sum_{i} p_{ig}\)</span></li>
</ul></li>
<li>Then the HL test statistic (<span class="math inline">\(H\)</span>) has a <span class="math inline">\(\chi^{2}\)</span> distribution and is is calculated as:</li>
</ol>
<p><span class="math display">\[ 
  H = \sum_{g=1}^{G}\left({\frac {(O_{1g}-E_{1g})^{2}}{E_{1g}}}+{\frac {(O_{0g}-E_{0g})^{2}}{E_{0g}}}\right) \sim \chi^{2}_{G-2}
\]</span></p>
</div>
<div id="hl-gof-in-r" class="section level4">
<h4><span class="header-section-number">4.2.4.2</span> HL GoF in R</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MKmisc)
<span class="kw">HLgof.test</span>(<span class="dt">fit =</span> <span class="kw">fitted</span>(me_intx_model), <span class="dt">obs =</span> me_intx_model<span class="op">$</span>y)
## $C
## 
##  Hosmer-Lemeshow C statistic
## 
## data:  fitted(me_intx_model) and me_intx_model$y
## X-squared = 2.2294e-16, df = 2, p-value = 1
## 
## 
## $H
## 
##  Hosmer-Lemeshow H statistic
## 
## data:  fitted(me_intx_model) and me_intx_model$y
## X-squared = 5.614e-17, df = 8, p-value = 1</code></pre></div>
<p>A very low test statistic and a very high p-value indicate that this model fits the data well.</p>
</div>
</div>
<div id="classification" class="section level3">
<h3><span class="header-section-number">4.2.5</span> Classification</h3>
<ul>
<li>Sometimes Odds Ratios can be difficult to interpret or understand.</li>
<li>Sometimes you just want to report the probability of the event occurring.</li>
<li>Or sometimes you want to predict whether or not a new individual is going to have the event.</li>
</ul>
<p>For all of these, we need to calculate <span class="math inline">\(p_{i} = P(y_{i}=1)\)</span>, the probability of the event.</p>
<p>For the main effects model of depression on age, income and gender the predicted probability of depression is: <span class="math display">\[
P(depressed) = \frac{e^{-0.676 - 0.02096*age - .03656*income + 0.92945*gender}}
{1 + e^{-0.676 - 0.02096*age - .03656*income + 0.92945*gender}}
\]</span></p>
<p>Let’s compare the probability of being depressed for males and females separately, while holding age and income constant at their average value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">depress <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarize</span>(<span class="dt">age=</span><span class="kw">mean</span>(age), <span class="dt">income=</span><span class="kw">mean</span>(income))
##        age   income
## 1 44.41497 20.57483</code></pre></div>
<p>Plug the coefficient estimates and the values of the variables into the equation and calculate. <span class="math display">\[
P(depressed|Female) = \frac{e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(1)}}
{1 + e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(1)}}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">XB.f &lt;-<span class="st"> </span><span class="op">-</span><span class="fl">0.676</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.02096</span><span class="op">*</span>(<span class="fl">44.4</span>) <span class="op">-</span><span class="st"> </span>.<span class="dv">03656</span><span class="op">*</span>(<span class="fl">20.6</span>) <span class="op">+</span><span class="st"> </span><span class="fl">0.92945</span>
<span class="kw">exp</span>(XB.f) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(XB.f))
## [1] 0.1930504</code></pre></div>
<p><span class="math display">\[
P(depressed|Male) = \frac{e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(0)}}
{1 + e^{-0.676 - 0.02096(44.4) - .03656(20.6) + 0.92945(0)}}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">XB.m &lt;-<span class="st"> </span><span class="op">-</span><span class="fl">0.676</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.02096</span><span class="op">*</span>(<span class="fl">44.4</span>) <span class="op">-</span><span class="st"> </span>.<span class="dv">03656</span><span class="op">*</span>(<span class="fl">20.6</span>)
<span class="kw">exp</span>(XB.m) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(XB.m))
## [1] 0.08629312</code></pre></div>
<p>The probability for a 44.4 year old female who makes $20.6k annual income has a 0.19 probability of being depressed. The probability of depression for a male of equal age and income is 0.86.</p>
</div>
<div id="calculating-predictions" class="section level3">
<h3><span class="header-section-number">4.2.6</span> Calculating predictions</h3>
<p>So what if you want to get the model predicted probability of the event for all individuals in the data set? There’s no way I’m doing that calculation for every person in the data set.</p>
<p>Using the main effects model from above, stored in the object <code>mvmodel</code>, we can call the <code>predict()</code> command to generate a vector of predictions for each row used in the model.</p>

<div class="rmdcaution">
Any row with missing data on any variable used in the model will NOT get a predicted value.
</div>

<p>The <code>predict()</code> function can calculate predictions for any GLM. The model object <code>mvmodel</code> stores the information that it was a logistic regression.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model.pred.prob &lt;-<span class="st"> </span><span class="kw">predict</span>(mvmodel, <span class="dt">type=</span><span class="st">&#39;response&#39;</span>)
<span class="kw">head</span>(model.pred.prob)
##          1          2          3          4          5          6 
## 0.21108906 0.08014012 0.15266203 0.24527840 0.15208679 0.17056409</code></pre></div>
<div id="distribution-of-predictions" class="section level4">
<h4><span class="header-section-number">4.2.6.1</span> Distribution of Predictions</h4>
<p>How well does our model do to predict depression?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
plot.mpp &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">prediction =</span> model.pred.prob, 
                       <span class="dt">truth =</span> <span class="kw">factor</span>(mvmodel<span class="op">$</span>y, <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;Not Depressed&quot;</span>, <span class="st">&quot;Depressed&quot;</span>)))

<span class="kw">ggplot</span>(plot.mpp, <span class="kw">aes</span>(<span class="dt">x=</span>truth, <span class="dt">y=</span>prediction, <span class="dt">fill=</span>truth)) <span class="op">+</span><span class="st"> </span>
<span class="st">      </span><span class="kw">geom_jitter</span>(<span class="dt">width=</span>.<span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_violin</span>(<span class="dt">alpha=</span>.<span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="GLM_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p><img src="images/q.png" /> What things can you infer from this plot?</p>
<p><img src="images/q.png" /> Where should we put the cutoff value? At what probability should we classify a record as “depressed”?</p>
</div>
</div>
<div id="model-performance" class="section level3">
<h3><span class="header-section-number">4.2.7</span> Model Performance</h3>
<ul>
<li>Say we decide that a value of 0.15 is our optimal cutoff value.</li>
<li>We can use this probability to classify each row into groups.
<ul>
<li>The assigned class values must match the data type and levels of the true value.</li>
<li>It also has to be in the same order, so the <code>0</code> group needs to come first.</li>
</ul></li>
<li>Then we calculate a <a href="https://en.wikipedia.org/wiki/Confusion_matrix">[Confusion Matrix]</a> using the similarly named function from the <code>caret</code> package.
<ul>
<li>At it’s core, this is a 2x2 table containing counts of each combination of predicted value and true value.</li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)

plot.mpp<span class="op">$</span>pred.class &lt;-<span class="st"> </span><span class="kw">ifelse</span>(plot.mpp<span class="op">$</span>prediction <span class="op">&lt;</span><span class="fl">0.15</span>, <span class="dv">0</span>,<span class="dv">1</span>)
plot.mpp<span class="op">$</span>pred.class &lt;-<span class="st"> </span><span class="kw">factor</span>(plot.mpp<span class="op">$</span>pred.class, <span class="dt">labels=</span><span class="kw">c</span>(<span class="st">&quot;Not Depressed&quot;</span>, <span class="st">&quot;Depressed&quot;</span>))

<span class="kw">confusionMatrix</span>(plot.mpp<span class="op">$</span>pred.class, plot.mpp<span class="op">$</span>truth, <span class="dt">positive=</span><span class="st">&quot;Depressed&quot;</span>)
## Confusion Matrix and Statistics
## 
##                Reference
## Prediction      Not Depressed Depressed
##   Not Depressed           123        10
##   Depressed               121        40
##                                           
##                Accuracy : 0.5544          
##                  95% CI : (0.4956, 0.6121)
##     No Information Rate : 0.8299          
##     P-Value [Acc &gt; NIR] : 1               
##                                           
##                   Kappa : 0.1615          
##  Mcnemar&#39;s Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.8000          
##             Specificity : 0.5041          
##          Pos Pred Value : 0.2484          
##          Neg Pred Value : 0.9248          
##              Prevalence : 0.1701          
##          Detection Rate : 0.1361          
##    Detection Prevalence : 0.5476          
##       Balanced Accuracy : 0.6520          
##                                           
##        &#39;Positive&#39; Class : Depressed       
## </code></pre></div>
<ul>
<li>123 people were correctly predicted to not be depressed (True Negative, <span class="math inline">\(n_{11}\)</span>)</li>
<li>121 people were incorrectly predicted to be depressed (False Positive, <span class="math inline">\(n_{21}\)</span>)</li>
<li>10 people were incorrectly predicted to not be depressed (False Negative, <span class="math inline">\(n_{12}\)</span>)</li>
<li>40 people were correctly predicted to be depressed (True Positive, <span class="math inline">\(n_{22}\)</span>)</li>
</ul>
<p>Other terminology:</p>
<ul>
<li><strong>Sensitivity/Recall/True positive rate</strong>: P(condition positive|predicted positive) = <code>40/(10+40) = .8</code></li>
<li><strong>Specificity/true negative rate</strong>: P(condition negative|predicted negative) = <code>123/(123+121) = .504</code></li>
<li><strong>Precision/positive predicted value</strong>: P(true positive | predicted positive) = <code>40/(121+40) = .2484</code></li>
<li><strong>Accuracy</strong>: (TP + TN)/ Total: <code>(40 + 123)/(40+123+121+10) = .5544</code></li>
<li><strong>Balanced Accuracy</strong>: <span class="math inline">\([(n_{11}/n_{.1}) + (n_{22}/n_{.2})]/2\)</span> - This is to adjust for class size imbalances (like in this example)</li>
<li><strong>F1 score</strong>: the harmonic mean of precision and recall. This ranges from 0 (bad) to 1 (good): <span class="math inline">\(2*\frac{precision*recall}{precision + recall}\)</span> = <code>2*(.2484*.8)/(.2484+.8) = .38</code></li>
</ul>
<div id="optimal-cutoff-value" class="section level4">
<h4><span class="header-section-number">4.2.7.1</span> Optimal Cutoff Value</h4>
<p>Often we adjust the cutoff value to improve accuracy. This is where we have to put our gut feeling of what probability constitutes “high risk”. For some models, this could be as low as 30%. It’s whatever the probability is that optimally separates the classes. Let’s look at two ways to visualize model performance as a function of cutoff.</p>
</div>
</div>
<div id="roc-curves" class="section level3">
<h3><span class="header-section-number">4.2.8</span> ROC Curves</h3>
<ul>
<li>We can create a Receiver operating characteristic (ROC) curve to help find that sweet spot.</li>
<li>ROC curves show the balance between sensitivity and specificity.</li>
<li>We’ll use the <a href="https://rocr.bioinf.mpi-sb.mpg.de/">[ROCR]</a> package. It only takes 3 commands:
<ul>
<li>calculate <code>prediction()</code> using the model</li>
<li>calculate the model <code>performance()</code> on both true positive rate and true negative rate for a whole range of cutoff values.</li>
<li><code>plot</code> the curve.
<ul>
<li>The <code>colorize</code> option colors the curve according to the probability cutoff point.</li>
</ul></li>
</ul></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ROCR)
pr &lt;-<span class="st"> </span><span class="kw">prediction</span>(model.pred.prob, mvmodel<span class="op">$</span>y)
perf &lt;-<span class="st"> </span><span class="kw">performance</span>(pr, <span class="dt">measure=</span><span class="st">&quot;tpr&quot;</span>, <span class="dt">x.measure=</span><span class="st">&quot;fpr&quot;</span>)
<span class="kw">plot</span>(perf, <span class="dt">colorize=</span><span class="ot">TRUE</span>, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">print.cutoffs.at=</span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">by=</span><span class="fl">0.1</span>)))
<span class="kw">abline</span>(<span class="dt">a=</span><span class="dv">0</span>, <span class="dt">b=</span><span class="dv">1</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="GLM_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>We can also use the <code>performance()</code> function and say we want to evaluate the <span class="math inline">\(f1\)</span> measure</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">perf.f1 &lt;-<span class="st"> </span><span class="kw">performance</span>(pr,<span class="dt">measure=</span><span class="st">&quot;f&quot;</span>)
<span class="kw">plot</span>(perf.f1)</code></pre></div>
<p><img src="GLM_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<p>ROC curves:</p>
<ul>
<li>Can also be used for model comparison: <a href="http://yaojenkuo.io/diamondsROC.html" class="uri">http://yaojenkuo.io/diamondsROC.html</a></li>
<li>The Area under the Curve an give you a measure of overall model accuracy by calculating the area under the curve (auc).</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">auc &lt;-<span class="st"> </span><span class="kw">performance</span>(pr, <span class="dt">measure=</span><span class="st">&#39;auc&#39;</span>)
auc<span class="op">@</span>y.values
## [[1]]
## [1] 0.695041</code></pre></div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="fitting-glms-in-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="categorical-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
